{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b24ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8497a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_valid = []\n",
    "y_valid = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "with open('X_train.csv', newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        X_train.append(row)\n",
    "\n",
    "with open('y_train.csv', newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        y_train.append(row)\n",
    "\n",
    "with open('X_test.csv', newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        X_test.append(row)\n",
    "        \n",
    "with open('y_test.csv', newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        y_test.append(row)\n",
    "        \n",
    "with open('X_valid.csv', newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        X_valid.append(row)\n",
    "        \n",
    "with open('y_valid.csv', newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        y_valid.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e28c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [[float(i) for i in item] for item in X_train]\n",
    "X_test = [[float(i) for i in item] for item in X_test]\n",
    "X_valid = [[float(i) for i in item] for item in X_valid]\n",
    "y_train = [[float(i) for i in item] for item in y_train]\n",
    "y_valid = [[float(i) for i in item] for item in y_valid]\n",
    "y_test = [[float(i) for i in item] for item in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58da3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "MAX_NUM_WORDS = 10000\n",
    "# Building the CNN Model\n",
    "# initilaizing the Sequential nature for CNN model\n",
    "model = Sequential()      \n",
    "# Adding the embedding layer which will take in maximum of 450 words as input and provide a 32 dimensional output of those words which belong in the top_words dictionary\n",
    "model.add(Embedding(MAX_NUM_WORDS, 32, input_length=35))\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(37, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54ce8b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 35, 32)            320000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 28, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 14, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 250)               112250    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 37)                9287      \n",
      "=================================================================\n",
      "Total params: 449,761\n",
      "Trainable params: 449,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b12e460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 - 30s - loss: 1.0023 - accuracy: 0.7232 - val_loss: 0.5231 - val_accuracy: 0.8572\n",
      "Epoch 2/10\n",
      "1563/1563 - 26s - loss: 0.4211 - accuracy: 0.8836 - val_loss: 0.4132 - val_accuracy: 0.8847\n",
      "Epoch 3/10\n",
      "1563/1563 - 26s - loss: 0.3147 - accuracy: 0.9094 - val_loss: 0.3863 - val_accuracy: 0.8913\n",
      "Epoch 4/10\n",
      "1563/1563 - 27s - loss: 0.2499 - accuracy: 0.9269 - val_loss: 0.3853 - val_accuracy: 0.8965\n",
      "Epoch 5/10\n",
      "1563/1563 - 26s - loss: 0.2003 - accuracy: 0.9403 - val_loss: 0.4002 - val_accuracy: 0.8962\n",
      "Epoch 6/10\n",
      "1563/1563 - 26s - loss: 0.1606 - accuracy: 0.9519 - val_loss: 0.4289 - val_accuracy: 0.8979\n",
      "Accuracy: 91.53%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "callback = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "# Fitting the data onto model\n",
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10, batch_size=128, verbose=2, callbacks=[callback])\n",
    "# Getting score metrics from our model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# Displays the accuracy of correct sentiment prediction over test data\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd97d748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
